{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPzClhglzABz6+oDihz/Qsa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RicottaChz/Pytorch_Youtube/blob/main/backpropagation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "68jYZ8m2FJCD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "DhisSciBuH8l"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action = \"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input\n",
        "input_tensor = torch.tensor([0.2, 0.1], dtype=torch.float64)\n",
        "\n",
        "# Define weights: w1, w2, b1, b2\n",
        "w1 = nn.Embedding(2, 2, dtype=torch.float64)\n",
        "w2 = nn.Embedding(2, 2, dtype=torch.float64)\n",
        "b1 = nn.Embedding(1, 2, dtype=torch.float64)\n",
        "b2 = nn.Embedding(1, 2, dtype=torch.float64)\n",
        "\n",
        "# Init weights: w1, w2, b1, b2\n",
        "w1.weight.data = torch.tensor([[0.2, 0.1], [0.4, 0.15]], dtype=torch.float64, requires_grad=True).t()\n",
        "w2.weight.data = torch.tensor([[0.65, 0.7], [0.45, 0.3]], dtype=torch.float64, requires_grad=True).t()\n",
        "b1.weight.data = torch.tensor([[0.3]], dtype=torch.float64, requires_grad=True).t()\n",
        "b2.weight.data = torch.tensor([[0.5]], dtype=torch.float64, requires_grad=True).t()"
      ],
      "metadata": {
        "id": "tvrFJq3r-LGL"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print weights\n",
        "print('*'*30)\n",
        "print('input_tensor:', input_tensor)\n",
        "print('*'*30)\n",
        "print('w1.weight:', w1.weight)\n",
        "# w1.weight.grad = None\n",
        "# If the optimizer.step() method is not called, that is, if backpropagation is not performed, the gradient of the weight is not obtained.\n",
        "print('w1.weight.grad:', w1.weight.grad)\n",
        "print('b1.weight:', b1.weight)\n",
        "print('b1.weight.grad:', b1.weight.grad)\n",
        "print('*'*30)\n",
        "print('w2.weight:', w2.weight)\n",
        "print('w2.weight.grad:', w2.weight.grad)\n",
        "print('b2.weight:', b2.weight)\n",
        "print('b2.weight.grad:', b2.weight.grad)\n",
        "print('*'*30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqGJRr_9-rF5",
        "outputId": "ff073205-c605-4f4b-9fe5-252f2322d178"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "******************************\n",
            "input_tensor: tensor([0.2000, 0.1000], dtype=torch.float64)\n",
            "******************************\n",
            "w1.weight: Parameter containing:\n",
            "tensor([[0.2000, 0.4000],\n",
            "        [0.1000, 0.1500]], dtype=torch.float64, requires_grad=True)\n",
            "w1.weight.grad: None\n",
            "b1.weight: Parameter containing:\n",
            "tensor([[0.3000]], dtype=torch.float64, requires_grad=True)\n",
            "b1.weight.grad: None\n",
            "******************************\n",
            "w2.weight: Parameter containing:\n",
            "tensor([[0.6500, 0.4500],\n",
            "        [0.7000, 0.3000]], dtype=torch.float64, requires_grad=True)\n",
            "w2.weight.grad: None\n",
            "b2.weight: Parameter containing:\n",
            "tensor([[0.5000]], dtype=torch.float64, requires_grad=True)\n",
            "b2.weight.grad: None\n",
            "******************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hidden layer (MLP)\n",
        "net_h1_h2 = torch.matmul(input_tensor, w1.weight) + b1.weight\n",
        "out_h1_h2 = F.relu(net_h1_h2)"
      ],
      "metadata": {
        "id": "iyXrCPwj-uh4"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [[net_h1, net_h2]]\n",
        "print('net_h1_h2:', net_h1_h2)\n",
        "# [[out_h1, out_h2]]\n",
        "print('out_h1_h2:', out_h1_h2)\n",
        "print('out_h1_h2.grad:', out_h1_h2.grad)\n",
        "\n",
        "# grad_fn 속성에는 tracking 된 연산이 저장"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBoDKIdKFgYV",
        "outputId": "4b45884c-0e95-464a-9d11-09bdd4b3c50b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "net_h1_h2: tensor([[0.3500, 0.3950]], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "out_h1_h2: tensor([[0.3500, 0.3950]], dtype=torch.float64, grad_fn=<ReluBackward0>)\n",
            "out_h1_h2.grad: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Output layer (MLP)\n",
        "net_o1_o2 = torch.matmul(out_h1_h2, w2.weight) + b2.weight\n",
        "out_o1_o2 = F.relu(net_o1_o2)"
      ],
      "metadata": {
        "id": "V91ir-pAFi7O"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [[net_o1, net_o2]]\n",
        "print('net_o1_o2:', net_o1_o2)\n",
        "# [[out_o1, out_o2]]\n",
        "print('out_o1_o2:', out_o1_o2)\n",
        "print('out_o1_o2.grad:', out_o1_o2.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnFn5O0uFp3C",
        "outputId": "5bc7437c-d3e1-40d6-f744-bda605fa45ed"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "net_o1_o2: tensor([[1.0040, 0.7760]], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "out_o1_o2: tensor([[1.0040, 0.7760]], dtype=torch.float64, grad_fn=<ReluBackward0>)\n",
            "out_o1_o2.grad: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label = torch.tensor([0.99, 0.01], dtype=torch.float64, requires_grad=True)"
      ],
      "metadata": {
        "id": "cKsOPdFVF17C"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function (MSE -> 1/n)\n",
        "loss = torch.sum(0.5*torch.square(label - out_o1_o2))\n",
        "print('loss:', loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siJvBE51F6pp",
        "outputId": "f55dc14c-9e11-4c38-eb59-739eb458038a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: tensor(0.2935, dtype=torch.float64, grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get gradient of each weight & bias\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "K-a1INWgGCA3"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradients\n",
        "# Save gradients in weight.grad attribute\n",
        "print('w1.weight.grad:', w1.weight.grad)\n",
        "print('b1.weight.grad:', b1.weight.grad)\n",
        "print('w2.weight.grad:', w2.weight.grad)\n",
        "print('b2.weight.grad:', b2.weight.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcYeaBpjGISu",
        "outputId": "b5c87ad6-fb55-47fb-b7ff-81076a5d7a24"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w1.weight.grad: tensor([[0.0708, 0.0479],\n",
            "        [0.0354, 0.0240]], dtype=torch.float64)\n",
            "b1.weight.grad: tensor([[0.5934]], dtype=torch.float64)\n",
            "w2.weight.grad: tensor([[0.0049, 0.2681],\n",
            "        [0.0055, 0.3026]], dtype=torch.float64)\n",
            "b2.weight.grad: tensor([[0.7800]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Before optimization\n",
        "# Weights\n",
        "print('w1.weight:', w1.weight)\n",
        "print('b1.weight:', b1.weight)\n",
        "print('w2.weight:', w2.weight)\n",
        "print('b2.weight:', b2.weight)\n",
        "# Loss\n",
        "h1 = F.relu(torch.matmul(input_tensor, w1.weight) + b1.weight)\n",
        "output = F.relu(torch.matmul(h1, w2.weight) + b2.weight)\n",
        "print('loss:', torch.sum(0.5*torch.square(label - output)))\n",
        "# Output\n",
        "print('label:', label)\n",
        "print('output:', output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaT-DfEgGK5z",
        "outputId": "82151a21-7dde-4407-c689-304c03d95a84"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w1.weight: Parameter containing:\n",
            "tensor([[0.2000, 0.4000],\n",
            "        [0.1000, 0.1500]], dtype=torch.float64, requires_grad=True)\n",
            "b1.weight: Parameter containing:\n",
            "tensor([[0.3000]], dtype=torch.float64, requires_grad=True)\n",
            "w2.weight: Parameter containing:\n",
            "tensor([[0.6500, 0.4500],\n",
            "        [0.7000, 0.3000]], dtype=torch.float64, requires_grad=True)\n",
            "b2.weight: Parameter containing:\n",
            "tensor([[0.5000]], dtype=torch.float64, requires_grad=True)\n",
            "loss: tensor(0.2935, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "label: tensor([0.9900, 0.0100], dtype=torch.float64, requires_grad=True)\n",
            "output: tensor([[1.0040, 0.7760]], dtype=torch.float64, grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning rate\n",
        "lr = 0.5\n",
        "# Optimizer\n",
        "optimizer = optim.SGD((w1.weight, w2.weight, b1.weight, b2.weight), lr=0.5)"
      ],
      "metadata": {
        "id": "qmMaqgBxGctJ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimization\n",
        "optimizer.step()"
      ],
      "metadata": {
        "id": "IyVxF-GFGfCo"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimization (1 epoch)\n",
        "# Optimizing weights\n",
        "print('w1.weight:', w1.weight)\n",
        "print('b1.weight:', b1.weight)\n",
        "print('w2.weight:', w2.weight)\n",
        "print('b2.weight:', b2.weight)\n",
        "# Decreasing loss\n",
        "h1 = F.relu(torch.matmul(input_tensor, w1.weight) + b1.weight)\n",
        "output = F.relu(torch.matmul(h1, w2.weight) + b2.weight)\n",
        "print('loss:', torch.sum(0.5*torch.square(label - output)))\n",
        "# More optimizing output\n",
        "print('label:', label)\n",
        "print('output:', output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5uALc4-GhWG",
        "outputId": "7a416597-f61d-443e-912b-5a0ae9b3a166"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w1.weight: Parameter containing:\n",
            "tensor([[0.1646, 0.3760],\n",
            "        [0.0823, 0.1380]], dtype=torch.float64, requires_grad=True)\n",
            "b1.weight: Parameter containing:\n",
            "tensor([[0.0033]], dtype=torch.float64, requires_grad=True)\n",
            "w2.weight: Parameter containing:\n",
            "tensor([[0.6476, 0.3160],\n",
            "        [0.6972, 0.1487]], dtype=torch.float64, requires_grad=True)\n",
            "b2.weight: Parameter containing:\n",
            "tensor([[0.1100]], dtype=torch.float64, requires_grad=True)\n",
            "loss: tensor(0.3177, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "label: tensor([0.9900, 0.0100], dtype=torch.float64, requires_grad=True)\n",
            "output: tensor([[0.2031, 0.1378]], dtype=torch.float64, grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1000 epochs\n",
        "for i in range(1000):\n",
        "\n",
        "    # Init gradient of optimizer\n",
        "    # If this method not called, gradient is stacked.\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Foward pass\n",
        "    h1 = F.relu(torch.matmul(input_tensor, w1.weight) + b1.weight)\n",
        "    output = F.relu(torch.matmul(h1, w2.weight) + b2.weight)\n",
        "\n",
        "    # Loss\n",
        "    loss = torch.sum(0.5*torch.square(label - output))\n",
        "\n",
        "    if i % 10 == 0:\n",
        "        # Decreasing loss\n",
        "        print('loss:', loss)\n",
        "\n",
        "    # Backward pass, compute gradient\n",
        "    loss.backward()\n",
        "\n",
        "    # Optimization\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SUTwesTGjXP",
        "outputId": "ad83e622-8692-446b-ac1c-53a928b620da"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: tensor(0.3177, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(0.0031, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.9206e-05, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.3337e-06, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(1.8680e-07, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(1.4961e-08, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(1.1984e-09, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(9.5996e-11, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(7.6899e-12, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(6.1601e-13, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(4.9346e-14, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(3.9529e-15, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(3.1666e-16, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.5366e-17, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.0320e-18, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(1.6278e-19, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(1.3039e-20, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(1.0446e-21, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(8.3676e-23, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(6.7026e-24, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(5.3725e-25, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(4.3149e-26, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(3.4870e-27, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.8676e-28, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.2985e-29, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.8047e-30, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(1.1583e-31, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.5749e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "loss: tensor(2.7434e-32, dtype=torch.float64, grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation of output (1000 epochs)\n",
        "h1 = F.relu(torch.matmul(input_tensor, w1.weight) + b1.weight)\n",
        "output = F.relu(torch.matmul(h1, w2.weight) + b2.weight)\n",
        "# Output: close to the label\n",
        "print('label:', label)\n",
        "print('output:', output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_xXimAUGnDp",
        "outputId": "6da734c7-ef53-4431-cb25-40623720cabe"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label: tensor([0.9900, 0.0100], dtype=torch.float64, requires_grad=True)\n",
            "output: tensor([[0.9900, 0.0100]], dtype=torch.float64, grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KlE5eTSUGpsr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}