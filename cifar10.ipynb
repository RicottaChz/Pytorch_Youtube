{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOogyEOhkr/PrJYwDQPxw7n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RicottaChz/Pytorch_Youtube/blob/main/cifar10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "637-0mvhLCB2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Load and Preprocessing\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "data_set = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "train_size = int(0.8 * len(data_set))\n",
        "val_size = len(data_set) - train_size\n",
        "train_set, val_set = torch.utils.data.random_split(data_set, [train_size, val_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=16,\n",
        "                                          shuffle=True, num_workers=2) # num_workers: how many subprocesses to use for data loading\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=16,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "test_set = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=16,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnndGb1DLC9W",
        "outputId": "f22bdbc7-7f41-49ad-b141-82e19f388852"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:04<00:00, 37275334.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "c7EjY0w6QTxL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(3, 6, 5) # input channel: 3, output channel: 6, kernel size: 5 / (32-5)/1 + 1 = 28 -> 6*28*28\n",
        "    self.pool = nn.MaxPool2d(2, 2)  # kernel size:2, stride:2 -> 6*14*14\n",
        "    self.conv2 = nn.Conv2d(6, 16, 5)  # input channel: 6, output channel: 16, kernel size: 5 / (14-5)/1 + 1 = 10 -> 16*10*10\n",
        "    self.fc1 = nn.Linear(16*5*5, 120)\n",
        "    self.fc2 = nn.Linear(120, 84)\n",
        "    self.out = nn.Linear(84, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.conv1(x)))\n",
        "    x = self.pool(F.relu(self.conv2(x)))\n",
        "    x = x.view(-1, 16*5*5)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.out(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "i99cwJ_qQYIz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()"
      ],
      "metadata": {
        "id": "YjRTQHOzSxNj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "Y9pDSNuwTBw8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for i, data in enumerate(train_loader, 0):\n",
        "    inputs, labels = data\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels.long())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if i % 1000 == 999:\n",
        "      print(f'Epoch: {epoch + 1}, Batch: {i + 1}, Loss: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaDuYGoeTVYw",
        "outputId": "cd901cee-0683-4a79-9499-33e7be65cb7c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Batch: 1000, Loss: 0.9463115334510803\n",
            "Epoch: 1, Batch: 2000, Loss: 1.2931841611862183\n",
            "Epoch: 2, Batch: 1000, Loss: 0.9879973530769348\n",
            "Epoch: 2, Batch: 2000, Loss: 0.7611536979675293\n",
            "Epoch: 3, Batch: 1000, Loss: 1.0597343444824219\n",
            "Epoch: 3, Batch: 2000, Loss: 1.3243061304092407\n",
            "Epoch: 4, Batch: 1000, Loss: 0.7541980147361755\n",
            "Epoch: 4, Batch: 2000, Loss: 1.021186113357544\n",
            "Epoch: 5, Batch: 1000, Loss: 1.5352925062179565\n",
            "Epoch: 5, Batch: 2000, Loss: 0.77165687084198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    for epoch in range(epochs):\n",
        "      for i, data in enumerate(val_loader, 0):\n",
        "        inputs, labels = data\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels.long())\n",
        "        if i % 200 == 199:\n",
        "          print(f'Epoch: {epoch + 1}, Batch: {i + 1}, Loss: {loss.item()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf9FPgequoRA",
        "outputId": "0247fc39-b03e-43ef-ebd7-6b922af50add"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Batch: 200, Loss: 1.0397984981536865\n",
            "Epoch: 1, Batch: 400, Loss: 1.1561123132705688\n",
            "Epoch: 1, Batch: 600, Loss: 1.0340701341629028\n",
            "Epoch: 2, Batch: 200, Loss: 1.3677239418029785\n",
            "Epoch: 2, Batch: 400, Loss: 1.419431447982788\n",
            "Epoch: 2, Batch: 600, Loss: 1.576132893562317\n",
            "Epoch: 3, Batch: 200, Loss: 0.9071974754333496\n",
            "Epoch: 3, Batch: 400, Loss: 0.5714786052703857\n",
            "Epoch: 3, Batch: 600, Loss: 1.339727520942688\n",
            "Epoch: 4, Batch: 200, Loss: 0.9577047228813171\n",
            "Epoch: 4, Batch: 400, Loss: 1.5387508869171143\n",
            "Epoch: 4, Batch: 600, Loss: 1.450723648071289\n",
            "Epoch: 5, Batch: 200, Loss: 1.0894684791564941\n",
            "Epoch: 5, Batch: 400, Loss: 1.2778403759002686\n",
            "Epoch: 5, Batch: 600, Loss: 0.876646876335144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p45KeXx6ZY0B",
        "outputId": "2d2c2b9f-7401-478b-9de8-cf09dd2dcc3d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the 10000 test images: 58 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Kx_8JT-fwCO",
        "outputId": "9c8ab72c-6206-4537-8570-52f245f7f958"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of plane : 66 %\n",
            "Accuracy of   car : 65 %\n",
            "Accuracy of  bird : 42 %\n",
            "Accuracy of   cat : 31 %\n",
            "Accuracy of  deer : 37 %\n",
            "Accuracy of   dog : 67 %\n",
            "Accuracy of  frog : 57 %\n",
            "Accuracy of horse : 72 %\n",
            "Accuracy of  ship : 76 %\n",
            "Accuracy of truck : 66 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v1gWLWwngCtj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}